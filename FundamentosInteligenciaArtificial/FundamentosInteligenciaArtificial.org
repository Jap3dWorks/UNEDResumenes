#+title: Fundamentos de inteligencia artificial
#+startup: latexpreview overview

* Aspectos conceptuales de la Inteligencia Artificial y la ingeniería del conocimiento
- Propósito general de la IA es desarrollar
      1. Modelos conceptuales
      2. Procedimientos de escritura formal de esos procedimientos
      3. Estratégias de programación y máquinas físicas para reproducir los mecanismos de inteligencia.
- 4 Objetivos de la IA son modelar, formalizar, programar e implementar máquinas soporte capaces de interactuar con el medio de forma no trivial.
- Aproximaciones dominantes
      - IA simbólica, via descendente y uso de conceptos del lenguaje natural para representar el conocimiento necesario para resolver problemas de decisión.
            - No requiere de un robot.
      - IA conexionismo situado, via ascendente y usos de conceptos de más bajo nivel semántico.
            - IA como forma superior de adaptación al medio (requiere robot).
- Carácter instrumental y objetivos
      - Ayudar a comoprender los procesos neurofisiológicos, cognitivos y sociales.
      - Prolongar los analizadores humanos y complementar sus deficiencias.

** IA como Ciencia y como IC
*** IA como Ciencia
- Tarea de análisis
- Engloba el conjunto de hechos asociados a la neurología y la cognición.
- Funciones globales de percepción, memoria, lenguaje, decisión, emoción y acción (acciones humanas).
      - Emergen de niveles subcelulares, neurológicos, etc.
- Busca una teoría computable del conocimiento humano.

*** IA como Ingeniería (IC)
- Nuevo objetivo de la IC es el conocimiento.
      - Usa la energía como soporte.
- El mensaje está en la estructura relacional y en el consenso entre los distintos observadores.
      - Deben dotar de significado a los símbolos formales y físicos que constituyen el cálculo.
- El conocimiento debe ser
      - Reutilizable
      - Impersonal
      - Transferible
      - Verificable experimentalmente
      - Con capacidad de predicción (como una ley física).
- No puede apoyarse en una sólida teoría del conoccimiento.
- Tareas que aborda la IC
      1. Tareas básicas como ver, oir, interpretar el medio, moverse, aprender, etc.
      2. Tareas cientifico-técnicas en dominios estrechos
             - Diagnosticar en medicina por ejemplo
- Procedimiento en *SBCs*, sistemas basados en el conocimiento
      1. Descripción en lenguaje natural de las interacciones de un humano con el entorno.
      2. Se modela la descripción con metamodelos (*paradigmas*).
             - Simbólico
             - Conexionista (neurona formal)
             - Situado
             - Híbrido
      3. Escritura formal de las inferencias y los "roles" estáticos y dinámicos de acuerdo con el paradigma elegido.
             - Tipos esenciales de conocimiento
                   - Situado, Interacción con el medio, un robot.
                   - No situado, Interfaz entre el sistema IA y el medio es humana.
      4. Programar los operadores para las interfaces físicas (no humanas).

** Paradigmas actuales en IA
- *Paradigma* como aproximación metodológica consensuada.

*** Paradigma Simbólico o representacional
- Se parte de una descripción en lenguaje natural que se intenta describir en reglas.
- Descripciones declarativas de un conjunto de conceptos.
- Otro conjunto de reglas de inferencia entre estos conceptos.
      - Reglas de manipulación.
- 3 tipos de tareas
      - Análisis
      - Síntesis, diseño y construcción con restricciones.
      - Modificación, ajuste de parámetros.
- Procesos básicos del razonamiento humano según Craik
      - Traslación del medio externo a una representación interna.
      - Derivación de los símbolos anteriores mediante procesos de inferencia (inductiva, deductiva y abductiva).
      - Retraslación de los nuevos símbolos derivados en término de acciones que vuelven al medio externo.
- Apropiada para aplicaciones en las que disponemos de conocimiento suficiente para especificar las reglas inferenciales y en aquellos procesos de aprendizaje inductivo en los que también disponemos de conocimiento para especificar las meta-reglas.

*** Paradigma Situado o reactivo
- También llamado basado en conductas.
- Toda acción y toda percepción están estructuralmente acopladas.
      - El sistema a modelar se encuentra en un medio con el que se realimenta.
            - Sensores y efectores específicos.
            - Para el sistema solo existe lo que puede ser representado por un sensor.
- La percepción en el medio de esquemas son las percepciones
      - Se implementa a bajo nivel.
- Cuando el agente decide la acción o secuencia de acciones a realizar basta con que las active.
      - Los patrones espaciotemporales de acción están precalculados.
- La función de decisión del agente es una asociación (tabla) o autómata finito.
- Se usa esencialmente en robótica y sistemas en tiempo real.

*** Paradigma Conexionista (RNAs)
- *RNAs*, redes de neuronas artificiales.
- Líneas numéricas etiquetadas para la entrada y salida de la red.
- La inferencia se resuelve mediante un clasificador numérico de naturaleza paraétrica.
      - El valor de los parámetros se ajusta mediante aprendizaje.
- Arquitectura modular organizada en capas fuertemente interconectado.
      - Procesadores elementales son las neuronas que evaluan una sencilla función de cálculo.
- Características distintivas
      - Clasificador numérico adaptativo que asocia los valores de un conjunto de observables con los valores de otro conjunto más reducido de clases (salidas de las neuronas de la última capa).
      - Una parte importante del conocimiento disponible se corresponde con la fase de análisis de datos.
            - Selección de variables de entrada y salida.
            - Tipo de cálculo local
            - Inicialización de pesos
      - Balance entre datos y conocimiento disponible y naturaleza de esos datos.
            - Datos etiquetados se usan en el aprendizaje supervisado.
            - Datos no etiquetados se usan para un preproceso y el aprendizaje autootganizativo.
- Representación de grafo.
      - Nodos son neuronas.
      - Arcos son pesos ajustables.
- Las salidas numéricas de la última capa se interpretan con etiquetas asociadas a las clases.
- Hay otra vertiente más basada en mecanismos inspirados por la biología
      - Conexionismo bioinspirado
        
*** Paradigma Híbrido
- La mayor parte de los problemas son de naturaleza híbrida.
- Muy usado en *Sistemas borrosos*, inferencias en las que se mezclan componentes neuronales y borrosas.
      - Adquirir conocimiento, conjuntos borrosos más etiquetas.
      - Pueden usarse entradas numéricas y tratarlas con neuronas convencionales.
      - Pueden definirse esquemas de cálculo neuroborroso (operadores borrosos(min, max)).
      - Subyace conocimiento simbólico usado para especificar las variables y sus rangos, definir funciones de pertenencia y para diseñar la topología inicial de la red.
- Criterios generales.
      - Analizar exigencias computacionales del problema y los recursos de los que disponemos.
      - Descomponer en subtareas e inferencias primitivas.
      - Operacionalización efectiva del esquema inferencial, con módulos simbólicos y neuronales.

* Lógica y representación del conocimiento

* Introducción a las técnicas de búsqueda
** Algunos ejemplos
*** Generación de planes de actuación de robots
- Un entorno de actuación y un robot con un repertorio finito de opciones.
- Programar un robot consiste en.
      - Funciones de percepcion del entorno.
      - Funciones de formulación de planes de actuación.
      - Funciones de seguimientos de los planes.
- Según pag 311 es un problema de optimización casi tipo *Ramificación y poda* o *vuelta atrás*.
      - se usa una función /mueve(x,y)/ para ir avanzando en la solución.

*** Problema de rutas óptimas en grafos        
- pag 312, habla del algoritmo de dijkstra y el del viajante de comercio (travelling salesman problem (TSP)) (ram. y poda).

*** Juegos con contrincante
- pag 313
- Juegos como damas o ajedrez.
- La idea es que cada jugador (ambos IA) eligan la jugada más favorable.

** Formulación de problemas de búsqueda
- Componentes principales de un *sistema de búsqueda*.
      - *Los estados*, todas las situaciones por las que el agente puede eventualmente pasar durante la solución del problema.
            - Implica la elección de el modelo de representación.
      - *Reglas u operadores*, modelan las acciones elementales que es capaz de realizar el agente.
            - La interpretación del coste de cada operador debe hacerse a partir de la función objetivo.
      - *La estratégia de control*, Decide el orden en que se van explorando los estados.
            - La *búsqueda a ciegas* implica visitar más estados.
            - *La búsqueda inteligente* debe implicar visitar menos estados.
- *Estados* y *operadores* definen en *espacio de búsqueda*.
      - Algunos *nodos* (representación de grafo) del espacio de búsqueda representan las soluciones.
- Un *algoritmo de búsqueda es completo* si siempre encuentra solución, en el caso que exista alguna.
- Un *algoritmo de búsqueda es admisible* o exacto si siempre encuentra una solución óptima.

** Métodos de búsqueda sin información
- Búsquedas de forma sistemática sin tener en cuenta nungún tipo de información sobre el dominio del problema.
- Se suele considerar un árbol como espacio de búsqueda.
      - El grafo para espacios de búsqueda más generales.

*** Recorrido de árboles
**** Primero en Anchura
- Es un *algoritmo completo*.
- Si todas las reglas tienen un coste de 1 es *admisible*.
- Tiempo de ejecución y el espacio de memoria crecen de forma exponencial.
- El número de nodos total (que pueden visitarse) de un árbol es una *sucesión geométrica*.
      - $\sum_{i=0}^d b^{i} = \frac{b^{d+1} - 1}{b-1}$
            - $b$ es el número de hijos de cada nodo, que puede ser el caso medio.
            - Se supone que el nivel 0 es de 1 solo nodo.

#+begin_src pseudocode
ABIERTA=(inicial)
mientras NoVacia(ABIERTA) hacer
    n <- ExtraePrimero(ABIERTA)
    
    si EsObjetivo(n) entonces
        dev Camino(inicial,n)
    fsi
    
    S = Sucesores(n)
    
    para cada q en S hacer
        pone q en la TABLA_A con         // TABLA_A almacena los datos de un estado de búsqueda
            Anterior(q) = n,
            Coste(inicial,q) <- Coste(inicial,n) + Coste(n,q)
        ABIERTA <- ABIERTA union {q}
    fpara
fmientras
dev "No encontrado"
#+end_src

**** Primero en profundidad
- No es una estratégia admisible ni completa, puede adentrarse en un rama infinita.
      - Suele establecerse una profundidad límite.
- Si la profundidad límite es $d$, el espacio requerido máximo es.
      - $(b-1)(b-2) + b$ para ABIERTA
      - $1+(d-1)b$ para TABLA_A
- Máximo de nodos visitados $\frac{b^{d+1}-1}{b-1}$

#+begin_src pseudocode
ABIERTA=(inicial)                 // Es una pila
mientras NoVacia(ABIERTA) hacer
    n=ExtraePrimero(ABIERTA)
    si EsObjetivo(n) entonces
        devolver Camino(inicial,n)
    fsi
    S={}
    si Profundidad(n) < ProdundidadLimite entonces
        S = Sucesores(n)
    fsi
    si Vacio(S) entonces
        LimpiarTabla_A(n)
    fsi
    para cada q en S hacer
        pone q en la TABLA_A con
            Anterior(q) <- n,
            Coste(inicial,1) <- Coste(inicial,n) + Coste(n,q),
            Profundidad(q) <- Profundidad(n) + 1
        Encola(q, ABIERTA)
    fpara
fmientras

dev "No encontrado"
#+end_src        

**** Coste uniforme
- En vez de usar una pila o una cola pueden insertarse los nodos en una estructura ordenada.
      - Se ordenan por coste desde el nodo inicial.
- Es un *algoritmo admisible*.

****   Búsquedas en profundidad y en anchura iterativas
- pag 320
- Búsqueda en profunidad que se va ampliando la produndidad límite si no se encuentra ninguna solución.

#+begin_src pseudocode
ProfundidadLimite <- 1
Solucion <- BusquedaPrimeroenProfundidad
mientras Solucion = "No encontrado" hacer
    Solucion <- BusquedaPrimeroenProfundidad
fmientras
dev Solucion
#+end_src

- Búsqueda en anchura que va ampliando la anchura límite si no se encuentra ninguna solución.

#+begin_src pseudocode
AnchuraLimite <- 0
mientras se pueda aumentar la AnchuraLimite hacer
    AnchuraLimite <- AnchuraLimite + 1
    ABIERTA <- (inicial)
    mientras NoVacia(ABIERTA) hacer
        n <- ExtraePrimero(ABIERTA)
        
        si EsObjetivo(n) entonces
            dev Camino(inicial,n)
        fsi
        
        S <- Sucesores(n,AnchuraLimite)  // AnchuraLimite limita el número
                                         //  de nodos sucesores
        para cada q en S hacer
            poner q en la TABLA_A con
                Anterior(q) <- n,
                Coste(inicial,q) <- Coste(inicial,n) + Coste(n,q)
                
            Encolar(q, ABIERTA)
        fpara
    fmientras
fmientras
dev "No encontrado"
#+end_src

*** Recorrido de grafos
- A veces el ábol no sirve para modelar los estados de una solución.
      - Por ejemplo en el cálculo de actuación de planes de un robot.

**** Algoritmo general de búsqueda en grafos (AGBG)
:PROPERTIES:
:ID:       c2bbf2c1-f380-4078-93f6-8b52f0e78859
:END:
- Grafo dirigido simple a partir de operadores o reglas de producción.
- Número de reglas con un coste $\leq \varepsilon$, $\varepsilon > 0$, debe ser finito.
- Grafo localmente finito, cada nodo tiene un número finito de sucesores.

#+begin_src pseudocode
// TABLA_A contiene el mejor camino encontrado desde inicial a cada nodo.
ABIERTA <- (inicial)
mientras NoVacia(ABIERTA) hacer
    n <- ExtraePrimero(ABIERTA)
    si EsObjetivo(n) entonces
        dev Camino(inicial, n)
    fsi

    S <- Sucesores(n)
    Añade S a la entrada n en TABLA_A
    
    para cada q de S hacer
        si q en TABLA_A entonces
            Rectificar(q,n,Coste(n,q))   // Se comprueba si el nuevo camino es mejor
            Ordenar(ABIERTA)             // Ordenación por coste
            // No se incluye en ABIERTA
        sino
            pone q en la TABLA_A con
                Anterior(q) <- n,
                Coste(inicial,q) <- Coste(inicial,n) + Coste(n,q)
            ABIERTA <- Mezclar(q, ABIERTA)  // Inserta q en abierta
                                            //  Según la posición la búsqueda será
                                            //  en profundidad o en anchura
        fsi
    fpara
fmientras
dev "No solución"
#+end_src

#+begin_src pseudocode
fun Rectificar(n,p,costepn)
    si (Coste(inicial,p) + costepn) < Coste(inicial,n) entonces
        modifica la entrada del nodo n en la TABLA_A con
            Coste(inicial,n) <- Coste(inicial,p) + costepn
            Anterior(n) <- p
        RectificarLista(n)
    fsi
ffun

fun RectificarLista(n)
    LISTA <- Sucesores(n)    // Registrados en la TABLA_A
    para cada q de LISTA hacer
        Rectificar(q,n,Coste(n,q))
    fpara
ffun
#+end_src

**** Búsqueda bidireccional
- Buscar simultáneamente en dos direcciones.
      - De inicio a los objetivos.
      - De los objetivos a inicio.
- La búsqueda se detiene cuando las fronteras (listas ABIERTA) tienen algún nodo en común.
- En lugar de exponencial a $d$ podrían ser dos algoritmos a $d/2$.
- Hay que conocer los estados objetivos.
- Almenos una de las búsquedas debe retener en memoria todos los estados visitados.
      - Por tanto búsqueda en anchura.
      - Por tanto el espacio requerido es exponencial en $d/2$.
- Requiere un método eficiente para comprobar intersecciones de las dos listas.
      - tablas Hash puede valer.

* Técnicas basadas en búsquedas heurística
- Tema 9
- *heurístico*, mecanismo que permita dirigir la búsqueda hacia zonas más prometedoras.
      - Ayudan a decidir cual es la mejor alternativa entre varias posibles.
      - A veces fallan en la predicción de la mejor alternativa.
      - Se busca que el tiempo *medio* para llegar a una solución mejore.
            - El caso peor puede llegar aser igual que una búsqueda a ciegas.
- *metareglas*, reglas sobre como utilizar las reglas (pag 342).
      - Indican bajo qué condiciones se aplica cada acción.

** Búsqueda primero el mejor (BF, Best First)
- Una función $f(x)$ indica un valor de lo prometedor que es cada nodo para ser expandido.
      - Los nodos más prometedores están al principio.
- A $f(x)$ se le denomina *función heurística de evaluación*.

** El algoritmo A*
- Especialización de *BF*.
- Sea $n$ un nodo cualquiera del espacio de búsqueda.
      - $g^*(n)$, es el *coste del camino de menor coste* desde el nodo inicial hasta $n$.
      - $h^*(n)$, *coste del camino más corto desde* $n$ al objetivo más cercano a $n$ (objetivo = solución).
      - $f^*(n)=g^*(n) + h^*(n)$. Es decir es el coste del camino más corto desde el inicial a los objetivos condicionado a pasar por el nodo $n$.
      - $C^* = f^*(inicial) = h^*(inicial)$, es el coste de la solución óptima.
- Se trabaja con aproximaciones de las anteriores funciones.
      - $g(n)$, es el coste del mejor camino desde el inicial a $n$ obtenido hasta el momento durante la búsqueda.
            - $g(n) \geq g^*(n)$.
      - $h(n)$, estimación positiva de $h^*(n)$, tal que $h(n)=0$ si $n$ es un objetivo.
            - $h(n) \geq 0$.
            - Es la *función heurística* o *heurístico*.
            - Definir $h(n)$ es un problema no trivial.
            - Es admisible si $h(n) \leq h^*(n)\ \forall n$
      - $f(n) = g(n) + h(n)$
- Se ordenan los nodos candidatos según el valor $f(n)$ de forma ascendente.

*** Descripción del algoritmo A*
- Basado en [[id:c2bbf2c1-f380-4078-93f6-8b52f0e78859][AGBG]]

#+begin_src pseudocode
ABIERTA <- (inicial);
mientras NoVacia(ABIERTA) hacer
    n = ExtraePrimero(ABIERTA)
    si EsObjetivo(n) entonces
        dev Camino(inicial,n)
    fsi
    
    S <- Sucesores(n)

    Añade S a la entrada de n en la TABLA_A

    para cada q de S hacer
        si (q en TABLA_A) entonces
            Rectificar(q,n,Coste(n,q))
            Ordenar(ABIERTA)
        sino
            pone q en la TABLA_A con
                Anterior(q) <- n
                g(q)        <- g(n) + Coste(n,q)
                h(q)        <- Heurístico(q)
            ABIERTA = Mezclar(q, ABIERTA)
        fsi
    fpara
fmientras
dev "No Solución"
#+end_src

- Función Rectificar

#+begin_src pseudocode
fun Rectificar(n,p,costepn)
    si (g(p) + costepn < g(n) entonces
        Modificar la entrada del nodo n en la TABLA_A con
            g(n)        <- g(p) + costepn
            Anterior(n) <- p
            RectificarLista(n)
    fsi
ffun

fun RectificarLista(n)
    LISTA <- Sucesores(n)        // Registrados en la TABLA_A
    para cada q de LISTA hacer
        Rectificar(q,n,Coste(n,q))
    fpara
ffun
#+end_src

*** Propiedades Formales
- $s$ estado inicial.
- $\Gamma$ conjunto nodos objetivo.
- $\Gamma^* \subseteq \Gamma$  conjunto de objetivos óptimos.
- $P_{n-n'}$ denota un camino simple desde el nodo $n$ al nodo $n'$.
- $P_{n-n'}$ camino óptimo desde $n$ a $n'$.
- $NodosEnAbierta\ \cup \ NodosExpandidos = NodosEncontrados$
      - La unión es disjunta.

**** Terminación y completitud
- $A^*$ es completo en grafos *localmente finitos* (teorema pag 346).
      - localmente finito, grafo infinito con un número finito de sucesores por nodo.

**** Admisibilidad del algoritmo A*
- Una función heurística $h$ es adimisble si $h(n) \leq h^*(n)\ \forall n$.
- Antes de que $A^*$ termine, existe un nodo $n'$ en ABIERTA tal que $f(n') \leq C^*$ (lema 9.1).
- $A^*$ es admisible (teorema 9.2).

**** Comparación de heurísticos admisibles
- Un heurístico $h_2$ está más informado que $h_1$ si los dos son adimisibles y $h_2(n) > h_1(n)\ \forall n$, $n$ no final.
      - $A_1^*$ usa $h_1$, $A_2^*$ usa $h_2$.
- $A_2^*$ domina a $A_1^*$ si los dos son admisibles y todo nodo expandido por $A_2^*$ también lo es para $A_1^*$.
- Una condición necesaria de expansión de un nodo $n$ es que $f(n) \leq C^*$ (teorema 9.3).
- Una condición suficiente de expansión de un nodo $n$ es que $f(n) < C^*$.
- Un camino $P$ desde el inicial $s$ a un nodo $n$ es *C-acotado*, si para todo $n'$ de $P$ se cumple que $g_P(n') + h(n') \leq C$.
      - Siendo $g_P(n')$ el coste desde $s$ a $n'$ a través del camino $P$.
      - *Estrictamente C-acotado* si $g_P(n') + h(n') < C$.
- Una condición suficiente para que $A^*$ expanda un nodo $n$ es que exista un camino estrictamente C*-acotado desde $s$ a $n$ (teorema 9.5).
- Una condición necesaria de expansión de un nodo $n$ es que exista un camino C*-acotado desde $s$ a $n$ (teorema 9.6).
- Si $A_2^*$ está más informado que $A_1^*$, entonces $A_2^*$ domina $A_1^*$ (teorema 9.7).

**** Heurísticos consistentes o monótonos  
- $h$ es *monótono* si para todo par de nodos $n$ y $n'$ se cumple que.
\begin{equation*}
h(n) \leq k(n,n') + h(n')
\end{equation*}  
- $k(n,n')$ representa el coste mínimo para ir de $n$ a $n'$, $\infty$ si no hay camino.
- $h$ es *consistente* si para todo par de nodos $n$ y $n'$ se cumple que
\begin{equation*}
h(n) \leq c(n,n') + h(n')
\end{equation*}
- $c(n,n')$ represetna el coste de la regla que lleva de $n$ a $n'$, $\infty$ si no existe esta regla.
- *Monotonía* y *consistencia* son propiedades equivalentes.
- Todo heurístico *monótono* es admisible.
- Si $h$ es monótono y $A^*$ elige el nodo $n$ para expansión, entonces se cumple que $g(n)=g^*(n)$. El camino encontrado hasta el momento desde $s$ a $n$ es óptimo.
- Si $h$ es monótono, la condición necesaria de expansión de un nodo $n$ es
\begin{equation*}
g^*(n) + h(n) \leq C^*
\end{equation*}
- Y la condición suficiente
\begin{equation*}
g^*(n) + h(n) < C^*
\end{equation*}
- $A_2^*$ domina *ampliamente* a $A_1^*$ si todo nodo expandido por $A_2^*$ es también expandido por $A_1^*$. Excepto quizás algunos nodos que cumplen $h_2(n)=h1(n)=C^* - g^*(n)$
- Si $h_2(n) \geq h_1(n)$ para todo $n$ y los dos son monótonos, entonces $A_2^*$ domina ampliamente a $A_1^*$.

*** Diseño de heurísticos simples  
- pag 353

*** Relajación de las condiciones de optimalidad
- pag 357
- Se plantea que $A^*$ sea más aficiente aunque pierda admisibilidad.

**** Ajuste de los pesos de g y h
- Ponderación estática.
\begin{equation*}
f_w(n) = (1-w)g(w) + wh(n),\ w \in [0,1]
\end{equation*}
- Se encuentra el mejor valor de $w$ de forma experimental.
      - Si $h$ es admisible el algoritmo es admisible en $0 \leq w \leq 1/2$
      - Si $h$ es admisible en algoritmo puede perder la admisibilidad en $1/2 \leq w \leq 1$

**** Algoritmos E-admisibles
- $\varepsilon -admisibles$
- Sacrifica la obtención de una solución óptima frente a mejoras del rendimiento.
- $\varepsilon$ controla el deterioro de la solución obtenida.
- Un algoritmo es $\varepsilon - admisible$ si siempre encuentra una solución con un coste menor de $(1 + \varepsilon)C^*$.

***** Ponderación dinámica
- Los pesos son dinámicos, cambian a lo largo del proceso.
      - $h$ tiene un mayor peso al inicio de la búsqueda.
      - Al final se reduce para asegurar una búsqueda en anchura.

\begin{equation*}
f(n) = g(n) + h(n) + \varepsilon (1-d(n)/N)h(n)
\end{equation*}

- $d(n)$ es la profundidad del nodo $n$.
- $N$ es una cota superior de la profuncidad de la mejor solución.
- $\varepsilon>0$ indica la desviación que estamos dispuestos a admitir.
- Su $h$ es admisible el algoritmo de ponderación dinámica es $\varepsilon -admisible$.

***** Algoritmo AE*
- Algoritmo $A\varepsilon^*$
- Dentro de ABIERTA se considera una sublista llamada FOCAL formada por nodos cuyo valor de $f$ no se separa más de un factor $(1+\varepsilon)$ del valor mínimo de $f$ en ABIERTA

\begin{equation*}
FOCAL = \{n \in ABIERTA\ |\ f(n) \leq (1+\varepsilon)min( \{ f(n') : \forall n' \in ABIERTA \}) \}
\end{equation*}

- Se desarrollan primero los nodos de la sublista FOCAL.
      - Se usa el heurístico $h'$, que da una estimación del esfuerzo computacional para llegar a una solución.
      - Puede darse el case que $h'=h$.

- Si $h$ es admisible, $A_\varepsilon^*$ es $\varepsilon -admisible$.        

*** Diseño sistemático de heurísticos
- pag 360
- *Método de relajación del problema*, Versiones simplificadas del problema con menos restricciones.
      - Se enuncia el problema con todas sus restricciones.
      - Se suponen versiones relajadas.
            - Se relajan subconjuntos de restricciones.
            - Hasta conseguir una versión suficientemente simple que pueda ser resuelto con un *algoritmo polinomial*.
- Todo heurístico $h$ obtenido por *relajación del problema* es monótono.              

** Búsqueda con memoria limitada  
- Basado en búsqueda en profundidad

*** Algoritmo IDA*
- pag 362
- Se establece una longitud límite para la búsqueda del problema igual a $f(inicial)$.
      - $f(inicial)$ es una cota inferior de la solución óptima.
      - Cada iteración descarta los nodos $n$ que $f(n)$ supere $f(inicial)$.
- Si en una iteración no se encuentra solución se realiza una nueva iteración.
      - Con una nueva longitud límite $f(inicio)$
            - El valor de $f(n)$ menor de los nodos descartados en la iteración anterior.

#+begin_src pseudocode
LongitudLimite <- f(inicial)
Solución <- Primero en Profundidad con Longitud Limitada
mientras Solución = "No encontrado" hacer
    LongitudLimite <- NuevaLongitudLimite
    Solución       <- Primero en Profundidad con Longitud Limitada
fmientras
dev Solución
#+end_src              

#+caption: Algoritmo de búsqueda heurística en profundidad en árboles con longitud limitada
#+begin_src pseudocode
ABIERTA <- (inicial)
mientras NoVacia(ABIERTA) hacer
    n <- ExtraePrimero(ABIERTA)
    si EsObjetivo(n) entonces
        dev Camino(inicial, n)
    fsi
    S <- {}
    si f(n) < LongitudLimite entonces
        LimpiarTABLA_A(n)
    fsi
    para cada q de S hacer
        pone q en la TABLA_A con
            Anterior(q) <- n,
            g(q)        <- Coste(inicial,n) + Coste(n,q),
            h(q)        <- Heurístico(q)
    fpara
    Ordena S según los valores de f de menor a mayor
    ABIERTA <- Concatenar(S, ABIERTA)
fmientras
dev "No encontrado", NuevaLongitudLimite
#+end_src

*** Algoritmo SMA*
- pag 364
- IDA* tiene el problema de que se vuelven a expandir muchos nodos.
- Cuando necesita expandir un nodo y no tiene espacio en TABLA_A, elimina un nodo de esta tabla y de ABIERTA.
      - Son llamados nodos olvidados, y son los menos prometedores (mayor valor de $f$ en ABIERTA).
- El algoritmo recuerda en cada nodo el mejor $f$ de los hijos de ese nodo que han sido olvidados.
      - Para no volver a explorar subárboles que han sido eliminados.
- SMA* mantiene en los nodos ancestros información acerca de la calidad del mejor camino en cada subárbol descartado.
- Cuando se descartan todos los sucesores de un nodo $n$, el algoritmo recuerda la estimación del mejor camino a través de $n$.

#+begin_src pseudocode
Inserta el inicial en ABIERTA y en la TABLA_A
mientras NoVacia(ABIERTA) hacer
    n <- Primero(ABIERTA)
    si EsObjetivo(n) entonces
        dev Camino(inicial,n)
    fsi
    s <- SiguienteSucesor(n)
    si (NoEsObjetivo(s) && Profundidad(s) = Limite) entonces
        f(s) <- infty
    sino
        f(s) <- max(f(n), g(s) + h(s))
    fsi
    si todos los sucesores de n han sido generados entonces
        Actualiza f(n) y el f de los ancestros de n
    fsi
    si todos los sucesores de n están en la TABLA_A entonces
        Elimina n de ABIERTA
    fsi
    si la TABLA_A está llena entonces
        Elimina de ABIERTA y de la TABLA_A el nodo con mayor f en ABIERTA y menor profundidad,
          actualizando la estimación del mejor nodo hijo olvidado en el padre del nodo eliminado
        Inserta el padre del nodo eliminado en ABIERTA si no está
    fsi
    Inserta s en ABIERTA y en la TABLA_A
fmientras
dev "No solución"
#+end_src  
        
- Propiedades principales
      - Es capaz de evolucionar utilizando la memoria que tenga disponible.
      - Evita estados repetidos en la medida en que la memoria se lo permita.
      - Es completo si la memoria disponible es suficiente para almacenar el camino a la solución menos profunda.
      - Es admisible si tiene suficiente memoria para almacenar el camino hasta la solución óptima menos profunda.
      - Si la memoria es suficiente para el árbol de búsqueda completo, la eficiencia de la búsqueda es óptima.
- No está resuelta la cuestión de si SMA* tiene una eficiencia mejor o igual que otro algoritmo dada la misma información heurística y la misma cantidad de memoria.

** Algoritmo Voraces
- pag 366

** Algoritmos de ramificación y poda
- pag 366

** Algoritmos de mejora iterativa o búsqueda local
- Para algunos problemas el nodo solución contiene toda la información necesaria.
      - El resto del camino es irrelevante (problemas TSP y N-reinas).
- La idea es partir de un estado solución e ir iterando con pequeñas mejoras.
      - Soluciones vecinas

#+caption: Esquema de un algoritmo de búsqueda local
#+begin_src pseudocode
S <- SolucionInicial
mientras ! CriterioDeTerminación hacer
    V <- SolucionesVecinas(S)
    EvaluarSoluciones(V)
    S1 <- Seleccion(V)
    si CriterioDeAceptacion entonces
        S <- S1
    fsi
fmientras
dev S
#+end_src        

*** Algoritmo de escalada o máximo gradiente
- El criterio de aceptación es que $S_1$ sea mejor o igual a $S$.
- Problemas de estancamiento.
      - *Óptimos locales*, en estos puntos todos los vecinos son peores.
      - *Regiones planas*, todos los vecinos tienen el mismo valor que la solución actual y la búsqueda es aleatoria.
      - *Crestas*, Puede ser complicado guiar la solución a través de una cresta hasta la solución global.
- *Multiarranque* Contra los estancamientos se puede reiniciar el algoritmo desde otro punto inicial.

*** Temple Simulado
- Se admite con una cierta probabilidad que $S_1$ sea peor a $S$.
- Se realiza una selección aleatoria entre los vecinos.
      - Si el vecino mejora la solución se acepta.
      - Si el vecino no mejora la solución se acepta con una probabilidad.
            - $T$ temperatura, Alta al inicio del algoritmo
                  - Mayor probabilidad de aceptación.
                  - $T=\alpha(t,T)$, función alpha.
                        - $t$ iteración actual
            - $\Delta E$ incremento de energía
- Requiere un ajuste muy fino de los parámetros.
  
#+begin_src pseudocode
S <- SolucionInicial
t <- 0
T <- T_0
mientras ! CriterioDeTerminación hacer
    S_1 <- SelecciónAleatoria(SolucionesVecinas(S))
    \DeltaE <- Coste(S_1) - Coste(S);
    si \DeltaE < 0 entonces
        S = S_1
    sino
        S <- S_1 con probabilidad e^(- \DeltaE/T)
    fsi
    t <- t + 1
    T <- \alpha(t,T)
fmientras
dev S
#+end_src

*** Búsqueda tabú
- pag 373
- Dispone de un mecanismo de memoria.
- Evita la generación de algunos vecinos dependiendo de la historia reciente.
      - Se registra información de cada movimiento.
- Pueden hacerse excepciones, *criterio de aspiración*,  si un movimiento tabú resulta que mejora la solución actual.
- Resulta complicado establecer los parámetros.
      - Criterio de aspiración.
      - Memoria del histórico.
      - Información que se registra.

* Glosario
- *Inferencia*, Razonamiento, proceso mediante el cual partiendo de unos hechos se deducen otros hechos.
      - *Inferencia deductiva*, A implica B, C implica B, etc.
      - *Inferencia abductiva*, aspiramos a obtener hipótesis.
            - Inferencia de hipótesis que pueden explicar un hecho.
            - Hechos con un cierto grado de certeza asociado.
      - *Inferencia inductiva*, A si y solo si (B o C o D).
            - A partir de la experiencia constatada.
- *Agente racional*, Agente que actúa con la intención de alcanzar el mejor resultado. Cuando hay incertidumbre el mejor resultado esperado.
- *RNN*, Redes neuronales recurrentes
- *CNN*, Redes neuronales convolucionales
- *GAN*, Redes generativas adversarias.
      - Redes neuronales no supervisadas pero basadas en auto-entrenamiento supervisado.
      - Indicadas para IA Generativa.
      - Juego de suma 0 entre.
            - Generador Genera instancias a partir de lo que aprende del dominio
            - Discriminador, trata de valorar si la instancia es del mundo real o generada.
- *VAE*, Autocodificadores variacionales.
- *GPT*, Generative pretained trasformer
- *Interpretabilidad*, propiedad de entender la relación entre los datos procesados y la solución propuesta.
- *Explicabilidad*, Capacidad de entender el razonamiento efectuado por la máquina.
- *Frugalidad*, Propiedad de los algoritmos de aprendizaje de necesitar pocos recursos para mostrar unas prestaciones aceptables.
      - Tanto en el uso como en el entrenamiento.


